{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**PREPROCESSING**"
      ],
      "metadata": {
        "id": "SmuznpLrIQmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wAb6nzeEwEs8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b357780b-7efb-4007-d5f4-556e77e7813b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_de52jWuz-M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "D57jaHZraJ-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"train_cdc.csv\")\n",
        "\n",
        "TARGET = \"price\"\n",
        "\n",
        "df[\"log_price\"] = np.log(df[TARGET])\n",
        "\n",
        "# ✅ Keep id for image mapping\n",
        "house_ids = df[\"id\"].astype(str).values\n",
        "\n",
        "# ❌ Remove non-tabular columns\n",
        "df = df.drop(columns=[TARGET, \"id\", \"date\", \"zipcode\"])"
      ],
      "metadata": {
        "id": "2CId4r8Vu_Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "num_cols.remove(\"log_price\")\n",
        "\n",
        "cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "print(\"Numerical columns:\", num_cols)\n",
        "print(\"Categorical columns:\", cat_cols)\n",
        "\n",
        "X = df.drop(columns=[\"log_price\"])\n",
        "y = df[\"log_price\"].values\n",
        "\n",
        "X_train, X_val, y_train, y_val, ids_train, ids_val = train_test_split(\n",
        "    X, y, house_ids,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "o_FCxp0tu_RO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e77e8c-6e04-4ac8-9ec5-0cd977f14936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numerical columns: ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
            "Categorical columns: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), num_cols),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "X_train_proc = preprocessor.fit_transform(X_train)\n",
        "X_val_proc   = preprocessor.transform(X_val)\n",
        "\n",
        "input_dim = X_train_proc.shape[1]"
      ],
      "metadata": {
        "id": "lP2-bi_Hu_OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL TRAINING**"
      ],
      "metadata": {
        "id": "2bCQfY0vInMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import os"
      ],
      "metadata": {
        "id": "oIWSyybUu_K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "\n",
        "inception = models.inception_v3(\n",
        "    weights=models.Inception_V3_Weights.IMAGENET1K_V1\n",
        ")\n",
        "\n",
        "inception.fc = nn.Identity()\n",
        "inception.AuxLogits.fc = nn.Identity()\n",
        "\n",
        "inception.eval().to(device)\n",
        "\n",
        "for p in inception.parameters():\n",
        "    p.requires_grad = False\n"
      ],
      "metadata": {
        "id": "RokhgSrwu_H1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6993ad1-63c8-44d0-9c34-cc1d73378b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104M/104M [00:00<00:00, 119MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),\n",
        "    transforms.ToTensor(),   # values in [0,1]\n",
        "])"
      ],
      "metadata": {
        "id": "ieaIUDzgu_Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_DIR = \"/content/drive/MyDrive/satell_images_cdc_zoom15/\"\n",
        "\n",
        "def build_image_path_dict(image_dir):\n",
        "    \"\"\"\n",
        "    Returns: {house_id: image_path}\n",
        "    \"\"\"\n",
        "    img_map = {}\n",
        "    for fname in os.listdir(image_dir):\n",
        "        if fname.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "            house_id = fname.split(\".\")[0]\n",
        "            img_map[house_id] = os.path.join(image_dir, fname)\n",
        "    return img_map\n",
        "image_path_dict = build_image_path_dict(IMAGE_DIR)\n",
        "print(\"Total images found:\", len(image_path_dict))\n"
      ],
      "metadata": {
        "id": "y90rsv-vu_Bs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b634725b-998b-4a8e-c467-2c496edbbd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images found: 16110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_embeddings_batched(\n",
        "    image_path_dict,\n",
        "    batch_size=32\n",
        "):\n",
        "    image_embeddings = {}\n",
        "\n",
        "    ids = list(image_path_dict.keys())\n",
        "\n",
        "    for i in tqdm(range(0, len(ids), batch_size), desc=\"Extracting embeddings\"):\n",
        "        batch_ids = ids[i:i + batch_size]\n",
        "        batch_imgs = []\n",
        "\n",
        "        for hid in batch_ids:\n",
        "            img = Image.open(image_path_dict[hid]).convert(\"RGB\")\n",
        "            img = img_transform(img)\n",
        "            batch_imgs.append(img)\n",
        "\n",
        "        batch_imgs = torch.stack(batch_imgs).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            emb = inception(batch_imgs)  # (B, 2048)\n",
        "\n",
        "        emb = emb.cpu().numpy()\n",
        "\n",
        "        for j, hid in enumerate(batch_ids):\n",
        "            image_embeddings[hid] = emb[j]\n",
        "\n",
        "    return image_embeddings\n"
      ],
      "metadata": {
        "id": "RFdAcQGtu--s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_embeddings = extract_embeddings_batched(\n",
        "    image_path_dict,\n",
        "    batch_size=32  # ideal for T4\n",
        ")\n",
        "np.save(\"/content/drive/MyDrive/image_embeddings.npy\", image_embeddings)\n",
        "print(\"Saved embeddings:\", len(image_embeddings))"
      ],
      "metadata": {
        "id": "mtke_t0kyvLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "944feb67-9978-4c0e-f143-05676b124e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting embeddings: 100%|██████████| 504/504 [02:43<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved embeddings: 16110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import issparse\n",
        "\n",
        "class FusionDataset(Dataset):\n",
        "    def __init__(self, X_tab, ids, y, image_embeddings):\n",
        "        if issparse(X_tab):\n",
        "            X_tab = X_tab.toarray()\n",
        "\n",
        "        self.X_tab = torch.tensor(X_tab, dtype=torch.float32)\n",
        "        self.X_img = torch.tensor(\n",
        "            np.vstack([image_embeddings[i] for i in ids]),\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X_tab[idx], self.X_img[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "eLPXwYGGu-7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_embeddings = np.load(\n",
        "    \"/content/drive/MyDrive/image_embeddings.npy\",\n",
        "    allow_pickle=True\n",
        ").item()\n",
        "\n",
        "for k in image_embeddings:\n",
        "    v = image_embeddings[k]\n",
        "    image_embeddings[k] = v / np.linalg.norm(v)\n",
        "\n",
        "train_ds = FusionDataset(\n",
        "    X_train_proc, ids_train, y_train, image_embeddings\n",
        ")\n",
        "\n",
        "val_ds = FusionDataset(\n",
        "    X_val_proc, ids_val, y_val, image_embeddings\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "nzo-MXuCu-4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TabularFCNet(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "\n",
        "class ImageHead(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class TabularHead(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 40),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class FusionRegressor(nn.Module):\n",
        "    def __init__(self, tab_input_dim):\n",
        "        super().__init__()\n",
        "        self.image_head = ImageHead()\n",
        "        self.tabular_head = TabularHead(tab_input_dim)\n",
        "        self.regressor = nn.Linear(64 + 40, 1)\n",
        "\n",
        "    def forward(self, x_tab, x_img):\n",
        "        img_feat = self.image_head(x_img)\n",
        "        tab_feat = self.tabular_head(x_tab)\n",
        "        fused = torch.cat([img_feat, tab_feat], dim=1)\n",
        "        return self.regressor(fused).squeeze(1)\n"
      ],
      "metadata": {
        "id": "VSKjclycXV0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tab_model = TabularFCNet(X_train_proc.shape[1]).to(device)"
      ],
      "metadata": {
        "id": "8FGUqJ83QPko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "optimizer_tab = torch.optim.Adam(tab_model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(198):\n",
        "    tab_model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for x_tab, _, y in train_loader:\n",
        "        x_tab, y = x_tab.to(device), y.to(device)\n",
        "\n",
        "        optimizer_tab.zero_grad()\n",
        "        y_pred = tab_model(x_tab)\n",
        "        loss = criterion(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer_tab.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"[Tab] Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "OerDGV67XVxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07413a82-1380-40bc-d67c-effa0cc28129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tab] Epoch 1 | Loss: 33.1910\n",
            "[Tab] Epoch 2 | Loss: 1.4414\n",
            "[Tab] Epoch 3 | Loss: 1.2948\n",
            "[Tab] Epoch 4 | Loss: 1.2044\n",
            "[Tab] Epoch 5 | Loss: 1.1062\n",
            "[Tab] Epoch 6 | Loss: 1.0920\n",
            "[Tab] Epoch 7 | Loss: 1.0077\n",
            "[Tab] Epoch 8 | Loss: 0.9827\n",
            "[Tab] Epoch 9 | Loss: 0.9773\n",
            "[Tab] Epoch 10 | Loss: 0.9379\n",
            "[Tab] Epoch 11 | Loss: 0.8830\n",
            "[Tab] Epoch 12 | Loss: 0.8974\n",
            "[Tab] Epoch 13 | Loss: 0.8434\n",
            "[Tab] Epoch 14 | Loss: 0.8288\n",
            "[Tab] Epoch 15 | Loss: 0.8181\n",
            "[Tab] Epoch 16 | Loss: 0.7751\n",
            "[Tab] Epoch 17 | Loss: 0.7627\n",
            "[Tab] Epoch 18 | Loss: 0.7541\n",
            "[Tab] Epoch 19 | Loss: 0.7496\n",
            "[Tab] Epoch 20 | Loss: 0.7124\n",
            "[Tab] Epoch 21 | Loss: 0.7261\n",
            "[Tab] Epoch 22 | Loss: 0.7154\n",
            "[Tab] Epoch 23 | Loss: 0.6856\n",
            "[Tab] Epoch 24 | Loss: 0.6763\n",
            "[Tab] Epoch 25 | Loss: 0.6649\n",
            "[Tab] Epoch 26 | Loss: 0.6500\n",
            "[Tab] Epoch 27 | Loss: 0.6319\n",
            "[Tab] Epoch 28 | Loss: 0.6423\n",
            "[Tab] Epoch 29 | Loss: 0.6322\n",
            "[Tab] Epoch 30 | Loss: 0.6096\n",
            "[Tab] Epoch 31 | Loss: 0.5997\n",
            "[Tab] Epoch 32 | Loss: 0.5986\n",
            "[Tab] Epoch 33 | Loss: 0.5741\n",
            "[Tab] Epoch 34 | Loss: 0.5814\n",
            "[Tab] Epoch 35 | Loss: 0.5541\n",
            "[Tab] Epoch 36 | Loss: 0.5442\n",
            "[Tab] Epoch 37 | Loss: 0.5304\n",
            "[Tab] Epoch 38 | Loss: 0.5207\n",
            "[Tab] Epoch 39 | Loss: 0.5110\n",
            "[Tab] Epoch 40 | Loss: 0.4945\n",
            "[Tab] Epoch 41 | Loss: 0.5007\n",
            "[Tab] Epoch 42 | Loss: 0.4915\n",
            "[Tab] Epoch 43 | Loss: 0.4646\n",
            "[Tab] Epoch 44 | Loss: 0.4745\n",
            "[Tab] Epoch 45 | Loss: 0.4616\n",
            "[Tab] Epoch 46 | Loss: 0.4562\n",
            "[Tab] Epoch 47 | Loss: 0.4407\n",
            "[Tab] Epoch 48 | Loss: 0.4439\n",
            "[Tab] Epoch 49 | Loss: 0.4252\n",
            "[Tab] Epoch 50 | Loss: 0.4286\n",
            "[Tab] Epoch 51 | Loss: 0.4244\n",
            "[Tab] Epoch 52 | Loss: 0.4261\n",
            "[Tab] Epoch 53 | Loss: 0.4030\n",
            "[Tab] Epoch 54 | Loss: 0.3889\n",
            "[Tab] Epoch 55 | Loss: 0.3993\n",
            "[Tab] Epoch 56 | Loss: 0.3876\n",
            "[Tab] Epoch 57 | Loss: 0.3776\n",
            "[Tab] Epoch 58 | Loss: 0.3840\n",
            "[Tab] Epoch 59 | Loss: 0.3717\n",
            "[Tab] Epoch 60 | Loss: 0.3740\n",
            "[Tab] Epoch 61 | Loss: 0.3526\n",
            "[Tab] Epoch 62 | Loss: 0.3568\n",
            "[Tab] Epoch 63 | Loss: 0.3421\n",
            "[Tab] Epoch 64 | Loss: 0.3453\n",
            "[Tab] Epoch 65 | Loss: 0.3403\n",
            "[Tab] Epoch 66 | Loss: 0.3316\n",
            "[Tab] Epoch 67 | Loss: 0.3267\n",
            "[Tab] Epoch 68 | Loss: 0.3195\n",
            "[Tab] Epoch 69 | Loss: 0.3283\n",
            "[Tab] Epoch 70 | Loss: 0.3067\n",
            "[Tab] Epoch 71 | Loss: 0.3186\n",
            "[Tab] Epoch 72 | Loss: 0.2945\n",
            "[Tab] Epoch 73 | Loss: 0.3004\n",
            "[Tab] Epoch 74 | Loss: 0.2920\n",
            "[Tab] Epoch 75 | Loss: 0.2867\n",
            "[Tab] Epoch 76 | Loss: 0.2873\n",
            "[Tab] Epoch 77 | Loss: 0.2782\n",
            "[Tab] Epoch 78 | Loss: 0.2798\n",
            "[Tab] Epoch 79 | Loss: 0.2788\n",
            "[Tab] Epoch 80 | Loss: 0.2778\n",
            "[Tab] Epoch 81 | Loss: 0.2684\n",
            "[Tab] Epoch 82 | Loss: 0.2716\n",
            "[Tab] Epoch 83 | Loss: 0.2646\n",
            "[Tab] Epoch 84 | Loss: 0.2691\n",
            "[Tab] Epoch 85 | Loss: 0.2581\n",
            "[Tab] Epoch 86 | Loss: 0.2599\n",
            "[Tab] Epoch 87 | Loss: 0.2467\n",
            "[Tab] Epoch 88 | Loss: 0.2446\n",
            "[Tab] Epoch 89 | Loss: 0.2472\n",
            "[Tab] Epoch 90 | Loss: 0.2518\n",
            "[Tab] Epoch 91 | Loss: 0.2419\n",
            "[Tab] Epoch 92 | Loss: 0.2412\n",
            "[Tab] Epoch 93 | Loss: 0.2396\n",
            "[Tab] Epoch 94 | Loss: 0.2339\n",
            "[Tab] Epoch 95 | Loss: 0.2357\n",
            "[Tab] Epoch 96 | Loss: 0.2338\n",
            "[Tab] Epoch 97 | Loss: 0.2287\n",
            "[Tab] Epoch 98 | Loss: 0.2373\n",
            "[Tab] Epoch 99 | Loss: 0.2279\n",
            "[Tab] Epoch 100 | Loss: 0.2212\n",
            "[Tab] Epoch 101 | Loss: 0.2246\n",
            "[Tab] Epoch 102 | Loss: 0.2247\n",
            "[Tab] Epoch 103 | Loss: 0.2188\n",
            "[Tab] Epoch 104 | Loss: 0.2162\n",
            "[Tab] Epoch 105 | Loss: 0.2088\n",
            "[Tab] Epoch 106 | Loss: 0.2185\n",
            "[Tab] Epoch 107 | Loss: 0.2103\n",
            "[Tab] Epoch 108 | Loss: 0.2070\n",
            "[Tab] Epoch 109 | Loss: 0.2097\n",
            "[Tab] Epoch 110 | Loss: 0.2068\n",
            "[Tab] Epoch 111 | Loss: 0.2016\n",
            "[Tab] Epoch 112 | Loss: 0.2092\n",
            "[Tab] Epoch 113 | Loss: 0.2013\n",
            "[Tab] Epoch 114 | Loss: 0.1992\n",
            "[Tab] Epoch 115 | Loss: 0.2035\n",
            "[Tab] Epoch 116 | Loss: 0.1989\n",
            "[Tab] Epoch 117 | Loss: 0.1987\n",
            "[Tab] Epoch 118 | Loss: 0.1997\n",
            "[Tab] Epoch 119 | Loss: 0.1942\n",
            "[Tab] Epoch 120 | Loss: 0.1935\n",
            "[Tab] Epoch 121 | Loss: 0.1953\n",
            "[Tab] Epoch 122 | Loss: 0.1907\n",
            "[Tab] Epoch 123 | Loss: 0.1894\n",
            "[Tab] Epoch 124 | Loss: 0.1909\n",
            "[Tab] Epoch 125 | Loss: 0.1897\n",
            "[Tab] Epoch 126 | Loss: 0.1839\n",
            "[Tab] Epoch 127 | Loss: 0.1844\n",
            "[Tab] Epoch 128 | Loss: 0.1846\n",
            "[Tab] Epoch 129 | Loss: 0.1808\n",
            "[Tab] Epoch 130 | Loss: 0.1783\n",
            "[Tab] Epoch 131 | Loss: 0.1829\n",
            "[Tab] Epoch 132 | Loss: 0.1818\n",
            "[Tab] Epoch 133 | Loss: 0.1761\n",
            "[Tab] Epoch 134 | Loss: 0.1796\n",
            "[Tab] Epoch 135 | Loss: 0.1762\n",
            "[Tab] Epoch 136 | Loss: 0.1747\n",
            "[Tab] Epoch 137 | Loss: 0.1759\n",
            "[Tab] Epoch 138 | Loss: 0.1687\n",
            "[Tab] Epoch 139 | Loss: 0.1686\n",
            "[Tab] Epoch 140 | Loss: 0.1678\n",
            "[Tab] Epoch 141 | Loss: 0.1729\n",
            "[Tab] Epoch 142 | Loss: 0.1672\n",
            "[Tab] Epoch 143 | Loss: 0.1628\n",
            "[Tab] Epoch 144 | Loss: 0.1624\n",
            "[Tab] Epoch 145 | Loss: 0.1617\n",
            "[Tab] Epoch 146 | Loss: 0.1655\n",
            "[Tab] Epoch 147 | Loss: 0.1683\n",
            "[Tab] Epoch 148 | Loss: 0.1616\n",
            "[Tab] Epoch 149 | Loss: 0.1614\n",
            "[Tab] Epoch 150 | Loss: 0.1603\n",
            "[Tab] Epoch 151 | Loss: 0.1570\n",
            "[Tab] Epoch 152 | Loss: 0.1582\n",
            "[Tab] Epoch 153 | Loss: 0.1569\n",
            "[Tab] Epoch 154 | Loss: 0.1546\n",
            "[Tab] Epoch 155 | Loss: 0.1564\n",
            "[Tab] Epoch 156 | Loss: 0.1543\n",
            "[Tab] Epoch 157 | Loss: 0.1545\n",
            "[Tab] Epoch 158 | Loss: 0.1540\n",
            "[Tab] Epoch 159 | Loss: 0.1537\n",
            "[Tab] Epoch 160 | Loss: 0.1544\n",
            "[Tab] Epoch 161 | Loss: 0.1530\n",
            "[Tab] Epoch 162 | Loss: 0.1528\n",
            "[Tab] Epoch 163 | Loss: 0.1498\n",
            "[Tab] Epoch 164 | Loss: 0.1478\n",
            "[Tab] Epoch 165 | Loss: 0.1453\n",
            "[Tab] Epoch 166 | Loss: 0.1464\n",
            "[Tab] Epoch 167 | Loss: 0.1447\n",
            "[Tab] Epoch 168 | Loss: 0.1457\n",
            "[Tab] Epoch 169 | Loss: 0.1479\n",
            "[Tab] Epoch 170 | Loss: 0.1422\n",
            "[Tab] Epoch 171 | Loss: 0.1441\n",
            "[Tab] Epoch 172 | Loss: 0.1395\n",
            "[Tab] Epoch 173 | Loss: 0.1392\n",
            "[Tab] Epoch 174 | Loss: 0.1418\n",
            "[Tab] Epoch 175 | Loss: 0.1418\n",
            "[Tab] Epoch 176 | Loss: 0.1430\n",
            "[Tab] Epoch 177 | Loss: 0.1389\n",
            "[Tab] Epoch 178 | Loss: 0.1431\n",
            "[Tab] Epoch 179 | Loss: 0.1342\n",
            "[Tab] Epoch 180 | Loss: 0.1340\n",
            "[Tab] Epoch 181 | Loss: 0.1347\n",
            "[Tab] Epoch 182 | Loss: 0.1339\n",
            "[Tab] Epoch 183 | Loss: 0.1350\n",
            "[Tab] Epoch 184 | Loss: 0.1386\n",
            "[Tab] Epoch 185 | Loss: 0.1309\n",
            "[Tab] Epoch 186 | Loss: 0.1315\n",
            "[Tab] Epoch 187 | Loss: 0.1316\n",
            "[Tab] Epoch 188 | Loss: 0.1319\n",
            "[Tab] Epoch 189 | Loss: 0.1335\n",
            "[Tab] Epoch 190 | Loss: 0.1274\n",
            "[Tab] Epoch 191 | Loss: 0.1297\n",
            "[Tab] Epoch 192 | Loss: 0.1320\n",
            "[Tab] Epoch 193 | Loss: 0.1253\n",
            "[Tab] Epoch 194 | Loss: 0.1248\n",
            "[Tab] Epoch 195 | Loss: 0.1228\n",
            "[Tab] Epoch 196 | Loss: 0.1251\n",
            "[Tab] Epoch 197 | Loss: 0.1265\n",
            "[Tab] Epoch 198 | Loss: 0.1238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tab_model.eval()\n",
        "for p in tab_model.parameters():\n",
        "    p.requires_grad = False"
      ],
      "metadata": {
        "id": "Xo-tpbnjXVub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fusion_model = FusionRegressor(X_train_proc.shape[1]).to(device)"
      ],
      "metadata": {
        "id": "Me1YYaJ6QW8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer_fusion = torch.optim.Adam(fusion_model.parameters(), lr=5e-4, weight_decay = 1e-4)\n",
        "\n",
        "for epoch in range(200):\n",
        "    # ---------- TRAIN ----------\n",
        "    fusion_model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for x_tab, x_img, y in train_loader:\n",
        "        x_tab = x_tab.to(device)\n",
        "        x_img = x_img.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            y_tab = tab_model(x_tab)\n",
        "            residual = y - y_tab\n",
        "\n",
        "        optimizer_fusion.zero_grad()\n",
        "        r_pred = fusion_model(x_tab, x_img)\n",
        "        loss = criterion(r_pred, residual)\n",
        "        loss.backward()\n",
        "        optimizer_fusion.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    # ---------- VALIDATION (R² on FINAL prediction) ----------\n",
        "    fusion_model.eval()\n",
        "    val_preds, val_targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_tab, x_img, y in val_loader:\n",
        "            x_tab = x_tab.to(device)\n",
        "            x_img = x_img.to(device)\n",
        "\n",
        "            y_tab = tab_model(x_tab)\n",
        "            r_pred = fusion_model(x_tab, x_img)\n",
        "\n",
        "            y_final = y_tab + r_pred\n",
        "\n",
        "            val_preds.append(y_final.cpu())\n",
        "            val_targets.append(y)\n",
        "\n",
        "    val_preds = torch.cat(val_preds).numpy()\n",
        "    val_targets = torch.cat(val_targets).numpy()\n",
        "\n",
        "    val_r2 = r2_score(val_targets, val_preds)\n",
        "\n",
        "    print(\n",
        "        f\"[Epoch {epoch+1:02d}] \"\n",
        "        f\"Fusion Train Loss: {train_loss:.4f} | \"\n",
        "        f\"Val R² (FINAL): {val_r2:.4f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "GQpTfsAeXrTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f10e19-67d2-48a4-dad4-d462b9b911bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 01] Fusion Train Loss: 0.0356 | Val R² (FINAL): 0.8822\n",
            "[Epoch 02] Fusion Train Loss: 0.0290 | Val R² (FINAL): 0.8837\n",
            "[Epoch 03] Fusion Train Loss: 0.0278 | Val R² (FINAL): 0.8853\n",
            "[Epoch 04] Fusion Train Loss: 0.0274 | Val R² (FINAL): 0.8868\n",
            "[Epoch 05] Fusion Train Loss: 0.0265 | Val R² (FINAL): 0.8869\n",
            "[Epoch 06] Fusion Train Loss: 0.0260 | Val R² (FINAL): 0.8876\n",
            "[Epoch 07] Fusion Train Loss: 0.0258 | Val R² (FINAL): 0.8885\n",
            "[Epoch 08] Fusion Train Loss: 0.0253 | Val R² (FINAL): 0.8857\n",
            "[Epoch 09] Fusion Train Loss: 0.0250 | Val R² (FINAL): 0.8886\n",
            "[Epoch 10] Fusion Train Loss: 0.0247 | Val R² (FINAL): 0.8872\n",
            "[Epoch 11] Fusion Train Loss: 0.0244 | Val R² (FINAL): 0.8891\n",
            "[Epoch 12] Fusion Train Loss: 0.0242 | Val R² (FINAL): 0.8881\n",
            "[Epoch 13] Fusion Train Loss: 0.0242 | Val R² (FINAL): 0.8875\n",
            "[Epoch 14] Fusion Train Loss: 0.0242 | Val R² (FINAL): 0.8897\n",
            "[Epoch 15] Fusion Train Loss: 0.0239 | Val R² (FINAL): 0.8890\n",
            "[Epoch 16] Fusion Train Loss: 0.0238 | Val R² (FINAL): 0.8886\n",
            "[Epoch 17] Fusion Train Loss: 0.0236 | Val R² (FINAL): 0.8877\n",
            "[Epoch 18] Fusion Train Loss: 0.0236 | Val R² (FINAL): 0.8896\n",
            "[Epoch 19] Fusion Train Loss: 0.0234 | Val R² (FINAL): 0.8888\n",
            "[Epoch 20] Fusion Train Loss: 0.0233 | Val R² (FINAL): 0.8865\n",
            "[Epoch 21] Fusion Train Loss: 0.0233 | Val R² (FINAL): 0.8887\n",
            "[Epoch 22] Fusion Train Loss: 0.0232 | Val R² (FINAL): 0.8867\n",
            "[Epoch 23] Fusion Train Loss: 0.0231 | Val R² (FINAL): 0.8877\n",
            "[Epoch 24] Fusion Train Loss: 0.0231 | Val R² (FINAL): 0.8876\n",
            "[Epoch 25] Fusion Train Loss: 0.0230 | Val R² (FINAL): 0.8879\n",
            "[Epoch 26] Fusion Train Loss: 0.0232 | Val R² (FINAL): 0.8879\n",
            "[Epoch 27] Fusion Train Loss: 0.0229 | Val R² (FINAL): 0.8890\n",
            "[Epoch 28] Fusion Train Loss: 0.0229 | Val R² (FINAL): 0.8887\n",
            "[Epoch 29] Fusion Train Loss: 0.0227 | Val R² (FINAL): 0.8892\n",
            "[Epoch 30] Fusion Train Loss: 0.0226 | Val R² (FINAL): 0.8827\n",
            "[Epoch 31] Fusion Train Loss: 0.0226 | Val R² (FINAL): 0.8874\n",
            "[Epoch 32] Fusion Train Loss: 0.0226 | Val R² (FINAL): 0.8889\n",
            "[Epoch 33] Fusion Train Loss: 0.0224 | Val R² (FINAL): 0.8865\n",
            "[Epoch 34] Fusion Train Loss: 0.0223 | Val R² (FINAL): 0.8844\n",
            "[Epoch 35] Fusion Train Loss: 0.0222 | Val R² (FINAL): 0.8893\n",
            "[Epoch 36] Fusion Train Loss: 0.0220 | Val R² (FINAL): 0.8889\n",
            "[Epoch 37] Fusion Train Loss: 0.0222 | Val R² (FINAL): 0.8847\n",
            "[Epoch 38] Fusion Train Loss: 0.0219 | Val R² (FINAL): 0.8853\n",
            "[Epoch 39] Fusion Train Loss: 0.0217 | Val R² (FINAL): 0.8876\n",
            "[Epoch 40] Fusion Train Loss: 0.0217 | Val R² (FINAL): 0.8875\n",
            "[Epoch 41] Fusion Train Loss: 0.0217 | Val R² (FINAL): 0.8868\n",
            "[Epoch 42] Fusion Train Loss: 0.0216 | Val R² (FINAL): 0.8861\n",
            "[Epoch 43] Fusion Train Loss: 0.0216 | Val R² (FINAL): 0.8867\n",
            "[Epoch 44] Fusion Train Loss: 0.0213 | Val R² (FINAL): 0.8894\n",
            "[Epoch 45] Fusion Train Loss: 0.0211 | Val R² (FINAL): 0.8869\n",
            "[Epoch 46] Fusion Train Loss: 0.0211 | Val R² (FINAL): 0.8872\n",
            "[Epoch 47] Fusion Train Loss: 0.0208 | Val R² (FINAL): 0.8864\n",
            "[Epoch 48] Fusion Train Loss: 0.0208 | Val R² (FINAL): 0.8864\n",
            "[Epoch 49] Fusion Train Loss: 0.0208 | Val R² (FINAL): 0.8851\n",
            "[Epoch 50] Fusion Train Loss: 0.0209 | Val R² (FINAL): 0.8865\n",
            "[Epoch 51] Fusion Train Loss: 0.0207 | Val R² (FINAL): 0.8874\n",
            "[Epoch 52] Fusion Train Loss: 0.0210 | Val R² (FINAL): 0.8882\n",
            "[Epoch 53] Fusion Train Loss: 0.0206 | Val R² (FINAL): 0.8862\n",
            "[Epoch 54] Fusion Train Loss: 0.0207 | Val R² (FINAL): 0.8862\n",
            "[Epoch 55] Fusion Train Loss: 0.0206 | Val R² (FINAL): 0.8840\n",
            "[Epoch 56] Fusion Train Loss: 0.0206 | Val R² (FINAL): 0.8852\n",
            "[Epoch 57] Fusion Train Loss: 0.0206 | Val R² (FINAL): 0.8856\n",
            "[Epoch 58] Fusion Train Loss: 0.0203 | Val R² (FINAL): 0.8887\n",
            "[Epoch 59] Fusion Train Loss: 0.0203 | Val R² (FINAL): 0.8864\n",
            "[Epoch 60] Fusion Train Loss: 0.0201 | Val R² (FINAL): 0.8860\n",
            "[Epoch 61] Fusion Train Loss: 0.0201 | Val R² (FINAL): 0.8831\n",
            "[Epoch 62] Fusion Train Loss: 0.0198 | Val R² (FINAL): 0.8883\n",
            "[Epoch 63] Fusion Train Loss: 0.0200 | Val R² (FINAL): 0.8863\n",
            "[Epoch 64] Fusion Train Loss: 0.0201 | Val R² (FINAL): 0.8852\n",
            "[Epoch 65] Fusion Train Loss: 0.0196 | Val R² (FINAL): 0.8886\n",
            "[Epoch 66] Fusion Train Loss: 0.0200 | Val R² (FINAL): 0.8868\n",
            "[Epoch 67] Fusion Train Loss: 0.0198 | Val R² (FINAL): 0.8856\n",
            "[Epoch 68] Fusion Train Loss: 0.0195 | Val R² (FINAL): 0.8858\n",
            "[Epoch 69] Fusion Train Loss: 0.0191 | Val R² (FINAL): 0.8859\n",
            "[Epoch 70] Fusion Train Loss: 0.0196 | Val R² (FINAL): 0.8868\n",
            "[Epoch 71] Fusion Train Loss: 0.0194 | Val R² (FINAL): 0.8868\n",
            "[Epoch 72] Fusion Train Loss: 0.0194 | Val R² (FINAL): 0.8862\n",
            "[Epoch 73] Fusion Train Loss: 0.0193 | Val R² (FINAL): 0.8860\n",
            "[Epoch 74] Fusion Train Loss: 0.0192 | Val R² (FINAL): 0.8861\n",
            "[Epoch 75] Fusion Train Loss: 0.0188 | Val R² (FINAL): 0.8868\n",
            "[Epoch 76] Fusion Train Loss: 0.0189 | Val R² (FINAL): 0.8869\n",
            "[Epoch 77] Fusion Train Loss: 0.0189 | Val R² (FINAL): 0.8858\n",
            "[Epoch 78] Fusion Train Loss: 0.0189 | Val R² (FINAL): 0.8884\n",
            "[Epoch 79] Fusion Train Loss: 0.0188 | Val R² (FINAL): 0.8885\n",
            "[Epoch 80] Fusion Train Loss: 0.0185 | Val R² (FINAL): 0.8874\n",
            "[Epoch 81] Fusion Train Loss: 0.0188 | Val R² (FINAL): 0.8843\n",
            "[Epoch 82] Fusion Train Loss: 0.0188 | Val R² (FINAL): 0.8850\n",
            "[Epoch 83] Fusion Train Loss: 0.0186 | Val R² (FINAL): 0.8863\n",
            "[Epoch 84] Fusion Train Loss: 0.0186 | Val R² (FINAL): 0.8839\n",
            "[Epoch 85] Fusion Train Loss: 0.0183 | Val R² (FINAL): 0.8873\n",
            "[Epoch 86] Fusion Train Loss: 0.0184 | Val R² (FINAL): 0.8878\n",
            "[Epoch 87] Fusion Train Loss: 0.0187 | Val R² (FINAL): 0.8856\n",
            "[Epoch 88] Fusion Train Loss: 0.0185 | Val R² (FINAL): 0.8856\n",
            "[Epoch 89] Fusion Train Loss: 0.0184 | Val R² (FINAL): 0.8867\n",
            "[Epoch 90] Fusion Train Loss: 0.0184 | Val R² (FINAL): 0.8859\n",
            "[Epoch 91] Fusion Train Loss: 0.0182 | Val R² (FINAL): 0.8876\n",
            "[Epoch 92] Fusion Train Loss: 0.0183 | Val R² (FINAL): 0.8885\n",
            "[Epoch 93] Fusion Train Loss: 0.0182 | Val R² (FINAL): 0.8874\n",
            "[Epoch 94] Fusion Train Loss: 0.0180 | Val R² (FINAL): 0.8849\n",
            "[Epoch 95] Fusion Train Loss: 0.0183 | Val R² (FINAL): 0.8859\n",
            "[Epoch 96] Fusion Train Loss: 0.0183 | Val R² (FINAL): 0.8857\n",
            "[Epoch 97] Fusion Train Loss: 0.0182 | Val R² (FINAL): 0.8880\n",
            "[Epoch 98] Fusion Train Loss: 0.0180 | Val R² (FINAL): 0.8853\n",
            "[Epoch 99] Fusion Train Loss: 0.0179 | Val R² (FINAL): 0.8877\n",
            "[Epoch 100] Fusion Train Loss: 0.0173 | Val R² (FINAL): 0.8855\n",
            "[Epoch 101] Fusion Train Loss: 0.0178 | Val R² (FINAL): 0.8841\n",
            "[Epoch 102] Fusion Train Loss: 0.0179 | Val R² (FINAL): 0.8861\n",
            "[Epoch 103] Fusion Train Loss: 0.0178 | Val R² (FINAL): 0.8857\n",
            "[Epoch 104] Fusion Train Loss: 0.0178 | Val R² (FINAL): 0.8877\n",
            "[Epoch 105] Fusion Train Loss: 0.0176 | Val R² (FINAL): 0.8866\n",
            "[Epoch 106] Fusion Train Loss: 0.0178 | Val R² (FINAL): 0.8860\n",
            "[Epoch 107] Fusion Train Loss: 0.0180 | Val R² (FINAL): 0.8843\n",
            "[Epoch 108] Fusion Train Loss: 0.0176 | Val R² (FINAL): 0.8859\n",
            "[Epoch 109] Fusion Train Loss: 0.0178 | Val R² (FINAL): 0.8853\n",
            "[Epoch 110] Fusion Train Loss: 0.0176 | Val R² (FINAL): 0.8867\n",
            "[Epoch 111] Fusion Train Loss: 0.0175 | Val R² (FINAL): 0.8875\n",
            "[Epoch 112] Fusion Train Loss: 0.0178 | Val R² (FINAL): 0.8859\n",
            "[Epoch 113] Fusion Train Loss: 0.0174 | Val R² (FINAL): 0.8836\n",
            "[Epoch 114] Fusion Train Loss: 0.0170 | Val R² (FINAL): 0.8850\n",
            "[Epoch 115] Fusion Train Loss: 0.0175 | Val R² (FINAL): 0.8852\n",
            "[Epoch 116] Fusion Train Loss: 0.0174 | Val R² (FINAL): 0.8859\n",
            "[Epoch 117] Fusion Train Loss: 0.0172 | Val R² (FINAL): 0.8872\n",
            "[Epoch 118] Fusion Train Loss: 0.0174 | Val R² (FINAL): 0.8871\n",
            "[Epoch 119] Fusion Train Loss: 0.0175 | Val R² (FINAL): 0.8840\n",
            "[Epoch 120] Fusion Train Loss: 0.0170 | Val R² (FINAL): 0.8846\n",
            "[Epoch 121] Fusion Train Loss: 0.0171 | Val R² (FINAL): 0.8850\n",
            "[Epoch 122] Fusion Train Loss: 0.0169 | Val R² (FINAL): 0.8844\n",
            "[Epoch 123] Fusion Train Loss: 0.0170 | Val R² (FINAL): 0.8852\n",
            "[Epoch 124] Fusion Train Loss: 0.0170 | Val R² (FINAL): 0.8847\n",
            "[Epoch 125] Fusion Train Loss: 0.0175 | Val R² (FINAL): 0.8835\n",
            "[Epoch 126] Fusion Train Loss: 0.0169 | Val R² (FINAL): 0.8852\n",
            "[Epoch 127] Fusion Train Loss: 0.0168 | Val R² (FINAL): 0.8829\n",
            "[Epoch 128] Fusion Train Loss: 0.0167 | Val R² (FINAL): 0.8825\n",
            "[Epoch 129] Fusion Train Loss: 0.0170 | Val R² (FINAL): 0.8853\n",
            "[Epoch 130] Fusion Train Loss: 0.0169 | Val R² (FINAL): 0.8863\n",
            "[Epoch 131] Fusion Train Loss: 0.0167 | Val R² (FINAL): 0.8846\n",
            "[Epoch 132] Fusion Train Loss: 0.0168 | Val R² (FINAL): 0.8828\n",
            "[Epoch 133] Fusion Train Loss: 0.0169 | Val R² (FINAL): 0.8844\n",
            "[Epoch 134] Fusion Train Loss: 0.0166 | Val R² (FINAL): 0.8865\n",
            "[Epoch 135] Fusion Train Loss: 0.0165 | Val R² (FINAL): 0.8867\n",
            "[Epoch 136] Fusion Train Loss: 0.0162 | Val R² (FINAL): 0.8867\n",
            "[Epoch 137] Fusion Train Loss: 0.0170 | Val R² (FINAL): 0.8841\n",
            "[Epoch 138] Fusion Train Loss: 0.0169 | Val R² (FINAL): 0.8827\n",
            "[Epoch 139] Fusion Train Loss: 0.0164 | Val R² (FINAL): 0.8876\n",
            "[Epoch 140] Fusion Train Loss: 0.0167 | Val R² (FINAL): 0.8856\n",
            "[Epoch 141] Fusion Train Loss: 0.0168 | Val R² (FINAL): 0.8868\n",
            "[Epoch 142] Fusion Train Loss: 0.0170 | Val R² (FINAL): 0.8860\n",
            "[Epoch 143] Fusion Train Loss: 0.0166 | Val R² (FINAL): 0.8861\n",
            "[Epoch 144] Fusion Train Loss: 0.0166 | Val R² (FINAL): 0.8861\n",
            "[Epoch 145] Fusion Train Loss: 0.0162 | Val R² (FINAL): 0.8863\n",
            "[Epoch 146] Fusion Train Loss: 0.0164 | Val R² (FINAL): 0.8857\n",
            "[Epoch 147] Fusion Train Loss: 0.0167 | Val R² (FINAL): 0.8854\n",
            "[Epoch 148] Fusion Train Loss: 0.0166 | Val R² (FINAL): 0.8842\n",
            "[Epoch 149] Fusion Train Loss: 0.0162 | Val R² (FINAL): 0.8849\n",
            "[Epoch 150] Fusion Train Loss: 0.0163 | Val R² (FINAL): 0.8852\n",
            "[Epoch 151] Fusion Train Loss: 0.0163 | Val R² (FINAL): 0.8818\n",
            "[Epoch 152] Fusion Train Loss: 0.0163 | Val R² (FINAL): 0.8839\n",
            "[Epoch 153] Fusion Train Loss: 0.0167 | Val R² (FINAL): 0.8868\n",
            "[Epoch 154] Fusion Train Loss: 0.0163 | Val R² (FINAL): 0.8837\n",
            "[Epoch 155] Fusion Train Loss: 0.0161 | Val R² (FINAL): 0.8830\n",
            "[Epoch 156] Fusion Train Loss: 0.0164 | Val R² (FINAL): 0.8853\n",
            "[Epoch 157] Fusion Train Loss: 0.0163 | Val R² (FINAL): 0.8847\n",
            "[Epoch 158] Fusion Train Loss: 0.0164 | Val R² (FINAL): 0.8841\n",
            "[Epoch 159] Fusion Train Loss: 0.0163 | Val R² (FINAL): 0.8821\n",
            "[Epoch 160] Fusion Train Loss: 0.0164 | Val R² (FINAL): 0.8831\n",
            "[Epoch 161] Fusion Train Loss: 0.0164 | Val R² (FINAL): 0.8863\n",
            "[Epoch 162] Fusion Train Loss: 0.0161 | Val R² (FINAL): 0.8860\n",
            "[Epoch 163] Fusion Train Loss: 0.0158 | Val R² (FINAL): 0.8865\n",
            "[Epoch 164] Fusion Train Loss: 0.0160 | Val R² (FINAL): 0.8838\n",
            "[Epoch 165] Fusion Train Loss: 0.0161 | Val R² (FINAL): 0.8845\n",
            "[Epoch 166] Fusion Train Loss: 0.0158 | Val R² (FINAL): 0.8858\n",
            "[Epoch 167] Fusion Train Loss: 0.0164 | Val R² (FINAL): 0.8836\n",
            "[Epoch 168] Fusion Train Loss: 0.0160 | Val R² (FINAL): 0.8824\n",
            "[Epoch 169] Fusion Train Loss: 0.0157 | Val R² (FINAL): 0.8849\n",
            "[Epoch 170] Fusion Train Loss: 0.0158 | Val R² (FINAL): 0.8835\n",
            "[Epoch 171] Fusion Train Loss: 0.0159 | Val R² (FINAL): 0.8839\n",
            "[Epoch 172] Fusion Train Loss: 0.0162 | Val R² (FINAL): 0.8854\n",
            "[Epoch 173] Fusion Train Loss: 0.0161 | Val R² (FINAL): 0.8862\n",
            "[Epoch 174] Fusion Train Loss: 0.0158 | Val R² (FINAL): 0.8845\n",
            "[Epoch 175] Fusion Train Loss: 0.0157 | Val R² (FINAL): 0.8826\n",
            "[Epoch 176] Fusion Train Loss: 0.0158 | Val R² (FINAL): 0.8854\n",
            "[Epoch 177] Fusion Train Loss: 0.0161 | Val R² (FINAL): 0.8832\n",
            "[Epoch 178] Fusion Train Loss: 0.0160 | Val R² (FINAL): 0.8840\n",
            "[Epoch 179] Fusion Train Loss: 0.0158 | Val R² (FINAL): 0.8824\n",
            "[Epoch 180] Fusion Train Loss: 0.0160 | Val R² (FINAL): 0.8828\n",
            "[Epoch 181] Fusion Train Loss: 0.0159 | Val R² (FINAL): 0.8829\n",
            "[Epoch 182] Fusion Train Loss: 0.0159 | Val R² (FINAL): 0.8847\n",
            "[Epoch 183] Fusion Train Loss: 0.0159 | Val R² (FINAL): 0.8843\n",
            "[Epoch 184] Fusion Train Loss: 0.0154 | Val R² (FINAL): 0.8824\n",
            "[Epoch 185] Fusion Train Loss: 0.0156 | Val R² (FINAL): 0.8843\n",
            "[Epoch 186] Fusion Train Loss: 0.0157 | Val R² (FINAL): 0.8836\n",
            "[Epoch 187] Fusion Train Loss: 0.0157 | Val R² (FINAL): 0.8829\n",
            "[Epoch 188] Fusion Train Loss: 0.0159 | Val R² (FINAL): 0.8842\n",
            "[Epoch 189] Fusion Train Loss: 0.0156 | Val R² (FINAL): 0.8824\n",
            "[Epoch 190] Fusion Train Loss: 0.0156 | Val R² (FINAL): 0.8824\n",
            "[Epoch 191] Fusion Train Loss: 0.0155 | Val R² (FINAL): 0.8808\n",
            "[Epoch 192] Fusion Train Loss: 0.0157 | Val R² (FINAL): 0.8829\n",
            "[Epoch 193] Fusion Train Loss: 0.0159 | Val R² (FINAL): 0.8809\n",
            "[Epoch 194] Fusion Train Loss: 0.0160 | Val R² (FINAL): 0.8864\n",
            "[Epoch 195] Fusion Train Loss: 0.0157 | Val R² (FINAL): 0.8833\n",
            "[Epoch 196] Fusion Train Loss: 0.0155 | Val R² (FINAL): 0.8845\n",
            "[Epoch 197] Fusion Train Loss: 0.0157 | Val R² (FINAL): 0.8818\n",
            "[Epoch 198] Fusion Train Loss: 0.0155 | Val R² (FINAL): 0.8822\n",
            "[Epoch 199] Fusion Train Loss: 0.0156 | Val R² (FINAL): 0.8828\n",
            "[Epoch 200] Fusion Train Loss: 0.0154 | Val R² (FINAL): 0.8842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_final(tab_model, fusion_model, loader):\n",
        "    tab_model.eval()\n",
        "    fusion_model.eval()\n",
        "\n",
        "    preds, targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_tab, x_img, y in loader:\n",
        "            x_tab = x_tab.to(device)\n",
        "            x_img = x_img.to(device)\n",
        "\n",
        "            y_tab = tab_model(x_tab)\n",
        "            r_pred = fusion_model(x_tab, x_img)\n",
        "\n",
        "            y_final = y_tab + r_pred\n",
        "\n",
        "            preds.append(y_final.cpu())\n",
        "            targets.append(y)\n",
        "\n",
        "    preds = torch.cat(preds).numpy()\n",
        "    targets = torch.cat(targets).numpy()\n",
        "    return preds, targets\n"
      ],
      "metadata": {
        "id": "M2OkD4QHXrPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "preds, targets = predict_final(tab_model, fusion_model, val_loader)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(targets, preds))\n",
        "r2 = r2_score(targets, preds)\n",
        "\n",
        "print(\"Final RMSE:\", rmse)\n",
        "print(\"Final R2:\", r2)"
      ],
      "metadata": {
        "id": "KbUcueM8XrNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bef492-f4e6-4955-ebc5-a34e21280528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final RMSE: 0.1787359293154698\n",
            "Final R2: 0.884232759475708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save only the weights (recommended)\n",
        "torch.save(fusion_model.state_dict(), \"/content/drive/MyDrive/fusion_model.pth\")\n"
      ],
      "metadata": {
        "id": "1byOZUttxAh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save only the weights (recommended)\n",
        "torch.save(tab_model.state_dict(), \"/content/drive/MyDrive/tabular_model.pth\")"
      ],
      "metadata": {
        "id": "I8EaH88Bjs5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREDICTION**"
      ],
      "metadata": {
        "id": "Bw7ltbAklDfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tab_model_path = \"/content/drive/MyDrive/tabular_model.pth\"\n",
        "fusion_model_path = \"/content/drive/MyDrive/fusion_model.pth\"\n",
        "\n",
        "tab_model.load_state_dict(torch.load(tab_model_path, map_location=device))\n",
        "fusion_model.load_state_dict(torch.load(fusion_model_path, map_location=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcH8oVc4ztd6",
        "outputId": "3c4e34bb-1427-4807-b311-47b248ca6131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_DIR = '/content/drive/MyDrive/satell_images_cdc_zoom15_test'"
      ],
      "metadata": {
        "id": "45qRipId1y2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load the test dataset\n",
        "test_df = pd.read_csv(\"test_cdc.csv\")\n",
        "\n",
        "# ✅ Keep id for image mapping and store for final submission\n",
        "test_house_ids = test_df[\"id\"].astype(str).values\n",
        "\n",
        "# ❌ Remove non-tabular columns consistent with training\n",
        "X_test = test_df.drop(columns=[\"id\", \"date\", \"zipcode\"])\n",
        "\n",
        "# 2. Preprocess tabular data using the pre-fitted 'preprocessor'\n",
        "X_test_proc = preprocessor.transform(X_test)\n",
        "\n",
        "# 3. Extract Image Embeddings for the Test Set\n",
        "# We use the existing build_image_path_dict and extract_embeddings_batched functions\n",
        "test_image_path_dict = build_image_path_dict(IMAGE_DIR)\n",
        "\n",
        "# Filter the dictionary to only include IDs present in the test set\n",
        "test_image_map = {hid: test_image_path_dict[hid] for hid in test_house_ids if hid in test_image_path_dict}\n",
        "\n",
        "print(f\"Extracting embeddings for {len(test_image_map)} test images...\")\n",
        "test_embeddings = extract_embeddings_batched(test_image_map, batch_size=32)\n",
        "\n",
        "# Apply L2 Normalization (same as done for training embeddings)\n",
        "for k in test_embeddings:\n",
        "    v = test_embeddings[k]\n",
        "    test_embeddings[k] = v / np.linalg.norm(v)\n",
        "\n",
        "# 4. Create a Prediction Dataset (Modified FusionDataset to handle missing 'y')\n",
        "class TestFusionDataset(Dataset):\n",
        "    def __init__(self, X_tab, ids, image_embeddings):\n",
        "        if issparse(X_tab):\n",
        "            X_tab = X_tab.toarray()\n",
        "        self.X_tab = torch.tensor(X_tab, dtype=torch.float32)\n",
        "        # Handle cases where an image might be missing by using a zero vector\n",
        "        self.X_img = torch.tensor(\n",
        "            np.vstack([image_embeddings.get(i, np.zeros(2048)) for i in ids]),\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_tab)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X_tab[idx], self.X_img[idx]\n",
        "\n",
        "test_ds = TestFusionDataset(X_test_proc, test_house_ids, test_embeddings)\n",
        "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
        "\n",
        "# 5. Run Inference\n",
        "tab_model.eval()\n",
        "fusion_model.eval()\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_tab, x_img in tqdm(test_loader, desc=\"Predicting\"):\n",
        "        x_tab, x_img = x_tab.to(device), x_img.to(device)\n",
        "\n",
        "        # Step 1: Base tabular prediction\n",
        "        y_tab = tab_model(x_tab)\n",
        "\n",
        "        # Step 2: Image-based residual prediction\n",
        "        r_pred = fusion_model(x_tab, x_img)\n",
        "\n",
        "        # Final log-price prediction = Tabular + Residual\n",
        "        y_final_log = y_tab + r_pred\n",
        "\n",
        "        # Convert back from log-scale to original price scale\n",
        "        y_final_price = torch.exp(y_final_log)\n",
        "\n",
        "        all_preds.append(y_final_price.cpu())\n",
        "\n",
        "# 6. Save Results\n",
        "test_predictions = torch.cat(all_preds).numpy()\n",
        "submission = pd.DataFrame({\n",
        "    \"id\": test_house_ids,\n",
        "    \"price\": test_predictions\n",
        "})\n",
        "\n",
        "submission.to_csv(\"test_predictions.csv\", index=False)\n",
        "print(\"Predictions saved to test_predictions.csv\")"
      ],
      "metadata": {
        "id": "_ilNJ7Qykcpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39089dd1-a09d-46d2-a31d-104e9f6430b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting embeddings for 5396 test images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting embeddings: 100%|██████████| 169/169 [02:36<00:00,  1.08it/s]\n",
            "Predicting: 100%|██████████| 85/85 [00:00<00:00, 479.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to test_predictions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = pd.read_csv(\"test_predictions.csv\")\n",
        "df_pred.shape"
      ],
      "metadata": {
        "id": "hoLORxITkcmv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b556a6d5-08df-419c-9640-cf99aed75a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5404, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}